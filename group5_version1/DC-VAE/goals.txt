Dual Contradistinctive Generative Autoencoder
https://arxiv.org/abs/2011.10063

Qualitatively, CIFAR-10 Samples will be reproduced like in Figure 3 (b) of the paper. 
Quantitatively, from Table 2, FID score of DC-VAE Sampling (ours) line on CIFAR-10 dataset will be reproduced.
In the paper the number of epoch, the batch size and which type of GPU is used are not mentioned. Since we don't have 
much computational resources, we chose a paper with published results at lowest resolution as possible in the first place. Since there is an ambiguity on training time
If we cannot match the required(unknown) training iterations in a reasonable time, we may get 10-15% worse results

—— version 1 submission —— 

- We did not have changed any of our goals.
- We are able to reach as low as 56 FID score in Sampling at CIFAR-10 dataset while in the paper 18 FID is reported.
- if you could not reproduce the results that you have targeted: what is your future work plan (discuss what is missing in your implementation / what might be buggy / etc.)?
The answer to this qustion is at the last paragraph of Challenges and Discussion part in the main.ipynb