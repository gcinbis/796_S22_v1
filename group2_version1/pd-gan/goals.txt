TITLE: PD-GAN: Probabilistic Diverse GAN for Image Inpainting
URL: https://arxiv.org/pdf/2105.02201.pdf

OUR MINIMUM GOALS:

QUALITATIVE EVALUATION: Figure 5. Qualitative comparisons with state-of-the-art methods on Place2.

Figure 6. Qualitative comparisons with state-of-the-art methods on CelebA-HQ

Note: We are still trying to find the real images on Figure 5 for Places2 dataset. On the other hand, we have real image of Figure 6 for CelebA-HQ dataset. If we don't able to find the images of Figure 5, we will use the images of Figure 6 for Qualitative comparisons.

QUANTITATIVE EVALUATION: 
Table 1. Numerical comparisons on the Place2 dataset -> FID SCORES (Last Row(Ours))


—— version 1 submission ——
1. Our goals have not changed. (Figure 5. and Table 1.)

2. We implemented the model as explained in the paper.
However, the paper explains the generator model poorly.
The paper explains only the structure of the generator and it does not explain any information such as channel size, kernel size, stride vs.
On the other hand, it doesn't have any information about discriminator. The explanation of FID calculation basics is also missing.
(More detailed explanations are in notebook.)

3. We were only able to train the model only Places2/sky dataset due to the computational limits.
We also didn't use Hard Mask in higher dimensions (image size>= 128) due to the computational limits.

4. You may find our qualitative and quantitative results in the notebook.
We achieved a result similar to our qualitative target.
We got better FID results than PC Model for the quantitative target. This was actually our goal.
You can find the FID results of our model and the PC-based model we use in the main.ipynb.
The FID metric trend shown by our model and the PC-based model is similar to that on paper. As the mask rate increased,
so did the FID results. Our model showed better results than the PC model in all ratios.
However, the FID values do not exactly match the ones on the paper.
